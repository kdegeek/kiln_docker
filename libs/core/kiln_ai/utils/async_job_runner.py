import asyncio
from dataclasses import dataclass
from typing import AsyncGenerator, Awaitable, Callable, List, TypeVar

T = TypeVar("T")


@dataclass
class Progress:
    complete: int | None = None
    total: int | None = None
    errors: int | None = None


class AsyncJobRunner:
    def __init__(self, concurrency: int = 1):
        if concurrency < 1:
            raise ValueError("concurrency must be â‰¥ 1")
        self.concurrency = concurrency

    async def run(
        self,
        jobs: List[T],
        run_job: Callable[[T], Awaitable[bool]],
    ) -> AsyncGenerator[Progress, None]:
        """
        Runs the jobs with parallel workers and yields progress updates.
        """
        complete = 0
        errors = 0
        total = len(jobs)

        # Send initial status
        yield Progress(complete=complete, total=total, errors=errors)

        worker_queue: asyncio.Queue[T] = asyncio.Queue()
        for job in jobs:
            worker_queue.put_nowait(job)

        # simple status queue to return progress. True=success, False=error
        status_queue: asyncio.Queue[bool] = asyncio.Queue()

        workers = []
        for _ in range(self.concurrency):
            task = asyncio.create_task(
                self._run_worker(worker_queue, status_queue, run_job)
            )
            workers.append(task)

        # Send status updates until workers are done, and they are all sent
        while not status_queue.empty() or not all(worker.done() for worker in workers):
            try:
                # Use timeout to prevent hanging if all workers complete
                # between our while condition check and get()
                success = await asyncio.wait_for(status_queue.get(), timeout=0.1)
                if success:
                    complete += 1
                else:
                    errors += 1

                yield Progress(complete=complete, total=total, errors=errors)
            except asyncio.TimeoutError:
                # Timeout is expected, just continue to recheck worker status
                # Don't love this but beats sentinels for reliability
                continue

        # These are redundant, but keeping them will catch async errors
        await asyncio.gather(*workers)
        await worker_queue.join()

    async def _run_worker(
        self,
        worker_queue: asyncio.Queue[T],
        status_queue: asyncio.Queue[bool],
        run_job: Callable[[T], Awaitable[bool]],
    ):
        while True:
            try:
                job = worker_queue.get_nowait()
            except asyncio.QueueEmpty:
                # worker can end when the queue is empty
                break
            try:
                success = await run_job(job)
                await status_queue.put(success)
            finally:
                # Always mark the dequeued task as done, even on exceptions
                worker_queue.task_done()
